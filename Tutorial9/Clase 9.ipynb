{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial de Big Data\n",
    "## Bienvenidos a la clase 9 \n",
    "\n",
    "**Objetivo:**  \n",
    "Que se familiaricen con las técnicas de Regularización de Ridge y Lasso\n",
    "\n",
    "### Temario:\n",
    "- Reglas de Slack\n",
    "- Preguntas del TP\n",
    "- Regularización con Ridge y Lasso\n",
    "- Ejemplo párctico con base de hitters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e72a07c7-f17d-4652-92b0-d61fc59ff02f",
    "_uuid": "818b7297508f313f548091247ae5b5f76bd22167"
   },
   "source": [
    "#### Modelos lineales regularizados con Ridge y Lasso\n",
    "\n",
    "Exploraremos brevemente el conjunto de datos \"Hitters\" y usaremos la libreria de sklearn para ajustar modelos lineales regularizados por Lasso (son las siglas en ingles para: operador de selección y contracción mínima absoluta) y Ridge con el fin de predecir el salario de los jugadores de béisbol.\n",
    "\n",
    "Esta es una adaptación a Python de R. Jordan Crouser de las páginas 251-254 de \"Introduction to Statistical Learning with Applications in R\" by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Leer el conjunto de datos y explorar la estructura de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "99fc62bf-3829-4f27-b14a-daf03ea1fdbf",
    "_uuid": "081d6fd0996ffaae083d41c97a7cb8999ad596d1"
   },
   "outputs": [],
   "source": [
    "# Importamos los paquetes necesarios\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les dejo la documentación para que puedan comparar:\n",
    "- [LogisticRegression()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) --> La técnica de regularización de L1 se llama Regresión de Lasso y la L2 se llama Regresión de Ridge\n",
    "- [linear_model()](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) --> [Lasso()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso) y [Ridge()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Lasso.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Ridge.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](hitters.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data set and drop missing values \n",
    "Hitters = pd.read_csv(\"Hitters.csv\").dropna() \n",
    "Hitters.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4d04dd3c-dca5-43be-9ee1-9e50c22d2285",
    "_uuid": "449b84af4123b8cea09c8516ede63430650a1194"
   },
   "source": [
    "#### 2. Preparar las X e Y que usaremos en el modelo\n",
    "\n",
    "Aquí seleccionamos las variables que utilizaremos en nuestro modelo y transformamos a dummies las que son strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Hitters.Salary\n",
    "# Creamos variables dummies para las variables string\n",
    "dummies = pd.get_dummies(Hitters[['League', 'Division', 'NewLeague']])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f3dc86b0-6170-4fc8-9ead-761fcd8374bc",
    "_uuid": "940ae403b30d3d5a109daa8e785bf2a72dfaeb5b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definimos las variables que incluiremos en el set de X.\n",
    "\n",
    "# Eliminamos salarios (porque es nuestra y) y las columnas de strings\n",
    "X_ = Hitters.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\n",
    "X = pd.concat([X_, dummies[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7f55cd39-e871-469e-9a17-830620d8b6b8",
    "_uuid": "1dc235f2b32d8f5e1ba03abdb0053f20182152ab"
   },
   "source": [
    "#### 3. Ajuste un conjunto de modelos de lazo\n",
    "\n",
    "Usamos la función Lasso () para realizar una regresión de lineal regularizada. La función Lasso () tiene un argumento alfa (es el λ pero con otro nombre) que se usa para ajustar el modelo.\n",
    "\n",
    "Generaremos una matriz de valores alfa que van desde muy grandes a muy pequeños, esencialmente cubriendo la gama completa de escenarios desde el modelo nulo que contiene solo la intersección, hasta el ajuste de mínimos cuadrados.\n",
    "\n",
    "Estandarizamos los datos y ajustamos los modelos Lasso para cada valor de alfa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e6927dde-9413-423c-bddb-4cb05c19c912",
    "_uuid": "b4f1fde76662793c2b042dbcc0bb9ddbc453e9a0"
   },
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(6,-2,50)*0.5\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c2f313bc-c727-470a-b1a1-82525773b3c9",
    "_uuid": "99eda127ab220362ec4314d814f8b18f03dce7f1"
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(max_iter=10000, normalize=True)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(X, y)\n",
    "    coefs.append(lasso.coef_)\n",
    "    \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d873bfe1-10fe-4de7-847a-71f8d9b8eb9a",
    "_uuid": "60a9b6feca173d8a201f4b36bf97999e28ae48c5"
   },
   "source": [
    "#### 4. Plot Lasso parámetro de ajuste alfa\n",
    "\n",
    "Ahora trazamos la relación entre alfa y los coeficientes, una línea para cada característica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3ff7f8f0-3d4b-4106-9802-459d87022102",
    "_uuid": "ec772a4afcbdfbd5fbb0b2cc98bd6616803d01d6"
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "12c85aac-92d6-408b-8347-69b3ff3faa87",
    "_uuid": "03d265fe680ec2adb21f6623232d93cd5b610ae9"
   },
   "source": [
    "En el lado derecho podemos ver el modelo nulo, que contiene solo la intersección. Esto se debe a una penalización muy alta. En el lado izquierdo casi no hay penalización. Observe que en la gráfica de coeficientes (dependiendo de la elección del parámetro de ajuste) algunos de los coeficientes son exactamente iguales a cero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "76e877d72c5054346c1cd1f575dba05d9ee6144b"
   },
   "source": [
    "#### 5. Lazo con validación cruzada \n",
    "\n",
    "Ahora dividimos las muestras en un conjunto de entrenamiento y un conjunto de prueba para estimar el error de prueba. Realizamos una validación cruzada de 10 veces para elegir el mejor alfa, reajustar el modo, calcular el error de prueba asociado e imprimir los mejores coeficientes de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "90214d58668cf5c5549cc31778a82f70834cd5c2"
   },
   "outputs": [],
   "source": [
    "# Usamos cross-validation para dividir la muestra en training y test sets\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "\n",
    "lassocv = LassoCV(alphas=None, cv=10, max_iter=100000, normalize=True)\n",
    "lassocv.fit(X_train, y_train)\n",
    "lasso.set_params(alpha=lassocv.alpha_)\n",
    "print(\"Alpha=\", lassocv.alpha_)\n",
    "lasso.fit(X_train, y_train)\n",
    "print(\"mse = \",mean_squared_error(y_test, lasso.predict(X_test)))\n",
    "print(\"best model coefficients:\")\n",
    "pd.Series(lasso.coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "873fdb1d5275d8d6ba931f111049dd35294e2485"
   },
   "source": [
    "Observamos que 13 de las 19 estimaciones de coeficientes son exactamente cero. Por lo tanto, Lasso tiene una ventaja sustancial sobre la regresión de Ridge en que realiza una selección de las variables del modelo. Para completar la imagen, necesitamos los resultados de validación cruzada correspondientes de la regresión de la cresta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "adb4f7f41adf5f02709b13f3b0f16be9921004a8"
   },
   "source": [
    "#### 6. Regresión con Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos elegir arbitrariamente el alpha usando $\\lambda = 4$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge2 = Ridge(alpha = 4, normalize = True)\n",
    "ridge2.fit(X_train, y_train)             \n",
    "pred2 = ridge2.predict(X_test)           \n",
    "print(pd.Series(ridge2.coef_, index = X.columns)) \n",
    "print(mean_squared_error(y_test, pred2))          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ECM con alpha = 4 es 106216. \n",
    "\n",
    "Ahora probemos que pasa con un alpha muy grande, por ej. $10^{10}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge3 = Ridge(alpha = 10**10, normalize = True)\n",
    "ridge3.fit(X_train, y_train)             \n",
    "pred3 = ridge3.predict(X_test)           \n",
    "print(pd.Series(ridge3.coef_, index = X.columns)) \n",
    "print(mean_squared_error(y_test, pred3))          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta gran penalización reduce los coeficientes en un grado muy grande, esencialmente reduciéndose a un modelo que contiene solo el intersepto. Esta contracción excesiva hace que el modelo sea más sesgado, lo que resulta en un ECM más alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, entonces ajustar un modelo de regresión de Ridge con alfa = 4 conduce a un MSE de prueba mucho más bajo que ajustar un modelo con solo una intersección. Ahora verificamos si existe algún beneficio al realizar la regresión de Ridge con alfa = 4 en lugar de simplemente realizar la regresión por mínimos cuadrados. (Recuerden que la MCO es simplemente una regresión de Ridge con alfa = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge2 = Ridge(alpha = 0, normalize = True)\n",
    "ridge2.fit(X_train, y_train)             \n",
    "pred = ridge2.predict(X_test)            \n",
    "print(pd.Series(ridge2.coef_, index = X.columns)) \n",
    "print(mean_squared_error(y_test, pred))           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hecho, el modelo con Ridge es mejor que el de mínimos cuadrados regulares al comparar los ECM.\n",
    "\n",
    "Como era de esperar, ninguno de los coeficientes es exactamente cero: por que la regresión de Ridge no realiza  selección de variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, en lugar de elegir arbitrariamente alfa $ = 4 $, sería mejor usar la validación cruzada para elegir el parámetro de ajuste alfa. \n",
    "\n",
    "#### Ridge con validación cruzada \n",
    "\n",
    "Nuevamente, realizamos una validación cruzada con k=10 para elegir el mejor alfa, reajustar el modo, calcular el error de prueba asociado e imprimir los mejores coeficientes de modelos. Esta vez regularizando con Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "58ebbe1a-348d-42e2-b795-4a64ca26e511",
    "_uuid": "113da53348b000e38056e91f17e0cb11507c32fc"
   },
   "outputs": [],
   "source": [
    "ridgecv = RidgeCV(alphas=alphas, normalize=True)\n",
    "ridgecv.fit(X_train, y_train)\n",
    "print(\"Alpha=\", ridgecv.alpha_)\n",
    "ridge6 = Ridge(alpha=ridgecv.alpha_, normalize=True)\n",
    "ridge6.fit(X_train, y_train)\n",
    "print(\"mse = \",mean_squared_error(y_test, ridge6.predict(X_test)))\n",
    "print(\"best model coefficients:\")\n",
    "pd.Series(ridge6.coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "49d1bc77ad9d6940cb7b96983c141219cb1ed77d"
   },
   "source": [
    "La performance de los modelos regularizados con Ridge y con Lasso con Cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3bf1ceaf43000a90f3df91d2d0227c432854cd9d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"mse ridge = \",mean_squared_error(y_test, ridge6.predict(X_test)))\n",
    "print(\"mse lasso = \",mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4c420efe-2199-4691-a07d-f1e8b078ef18",
    "_uuid": "ac7930be5f4e0c50b46609768024b3e8b069b97c"
   },
   "source": [
    "#### Resumen\n",
    "Con alfa elegido por validación cruzada en este ejemplo, la prueba MSE del Lasso es un poco peor que la prueba MSE de regresión de Ridge. \n",
    "\n",
    "El lazo tiene una gran ventaja sobre la regresión de crestas, ya que produce modelos más simples e interpretables que involucran solo a un subconjunto de predictores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
